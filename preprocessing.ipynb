{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db8ebfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preamble\n",
    "import glob\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "from utils import train, predict, score_fluoroscopy, score_time, score_xray, score_retries_cannulated_dhs, score_retries_hansson, \\\n",
    "                drill_dist_hansson, guidewire_dist, drill_dist_hansson\n",
    "from skimage.io import imread_collection\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from unittest import TestLoader\n",
    "import numpy as np\n",
    "import glob\n",
    "import PIL.Image as Image\n",
    "from tqdm.notebook import tqdm\n",
    "plt.style.use('seaborn')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b56d4e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmacaroni\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.11 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem at: /tmp/ipykernel_23762/349631622.py 5 <module>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_23762/349631622.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"ort-project\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"ditteblom\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreinit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[1;32m    971\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"interrupted\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m         \u001b[0merror_seen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[1;32m    949\u001b[0m         \u001b[0mexcept_exit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_except_exit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 951\u001b[0;31m             \u001b[0mrun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    952\u001b[0m             \u001b[0mexcept_exit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_except_exit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mrun_obj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 629\u001b[0;31m         \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate_run_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    630\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_global_run_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/wandb/sdk/interface/interface.py\u001b[0m in \u001b[0;36mcommunicate_run_start\u001b[0;34m(self, run_pb)\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0mrun_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRunStartRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mrun_start\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_pb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_communicate_run_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/wandb/sdk/interface/interface_shared.py\u001b[0m in \u001b[0;36m_communicate_run_start\u001b[0;34m(self, run_start)\u001b[0m\n\u001b[1;32m    421\u001b[0m     ) -> Optional[pb.RunStartResponse]:\n\u001b[1;32m    422\u001b[0m         \u001b[0mrec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_communicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/wandb/sdk/interface/interface_shared.py\u001b[0m in \u001b[0;36m_communicate\u001b[0;34m(self, rec, timeout, local)\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrec\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRecord\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     ) -> Optional[pb.Result]:\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_communicate_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_communicate_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrec\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRecord\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mMessageFuture\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/wandb/sdk/interface/router.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"pb.Result\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mis_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object_ready\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_set\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# set up weights and biases (wandb.ai)\n",
    "\n",
    "import wandb\n",
    "\n",
    "wandb.init(project = \"ort-project\", entity = \"ditteblom\", reinit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b700a1",
   "metadata": {},
   "source": [
    "Create the dataset as a torch dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a41eca80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class SimulationData(torch.utils.data.Dataset):\n",
    "    def __init__(self, repair_type, split, transform = None, data_path = \"Data\", train_size = 0.8, test_size = 0.2, seed = 8):\n",
    "        'Initializing data'\n",
    "        self.data_path = data_path\n",
    "        self.repair_type = repair_type + \"/001_copenahgen_test_1\"\n",
    "        #self.type = type\n",
    "        self.transform = transform\n",
    "\n",
    "        img_files = glob.glob(self.data_path + '***/**/*.jpg', recursive=True)\n",
    "        img_files = [ x for x in img_files if self.repair_type in x ]\n",
    "        score_files = glob.glob(self.data_path + '***/**/*.txt', recursive=True)\n",
    "        score_files = [ x for x in score_files if self.repair_type in x ]\n",
    "        scores = []\n",
    "        scores_true = []\n",
    "        maxscore = 0\n",
    "                \n",
    "        for file in score_files:\n",
    "            with open(file) as f:\n",
    "                lines = f.read()\n",
    "            idx_score_end = lines.find('Score')\n",
    "            tmp = lines[:idx_score_end]\n",
    "            idx_score_start = tmp.rfind('\\n')\n",
    "            score = np.double(lines[idx_score_start+1:idx_score_end-4])\n",
    "\n",
    "            if maxscore == 0:\n",
    "              idx_maxscore_end = lines.find('Max score')\n",
    "              tmp = lines[:idx_maxscore_end]\n",
    "              idx_maxscore_start = tmp.rfind('\\n')\n",
    "              maxscore = np.double(lines[idx_maxscore_start+1:idx_maxscore_end-3])\n",
    "\n",
    "            scores_true.append(score/maxscore)\n",
    "\n",
    "            # find variables to be corrected in score\n",
    "            if repair_type == \"001_hansson_pin_system\":\n",
    "              var_score = []\n",
    "              variables = [\"Fluoroscopy\", \"Total time\", \"Nr of X-rays\", \"Nr of retries\", \"Distal drill distance to joint surface (mm)\",\n",
    "                          \"Guide wire distance to joint surface (mm)\", \"Proximal drill distance to joint surface (mm)\"]\n",
    "              for var in variables:\n",
    "                idx_end = lines.find(var)\n",
    "                tmp = lines[:idx_end]\n",
    "                idx_start = tmp.rfind('\\n')\n",
    "                var_score.append(np.double(lines[idx_start+1:idx_end-4]))\n",
    "\n",
    "              score += score_fluoroscopy(var_score[0])\n",
    "              score += score_time(var_score[1])\n",
    "              score += score_xray(var_score[2])\n",
    "              score += score_retries_hansson(var_score[3])\n",
    "              score += drill_dist_hansson(var_score[4])\n",
    "              score += guidewire_dist(var_score[5])\n",
    "              score += drill_dist_hansson(var_score[6])\n",
    "\n",
    "              if score > maxscore:\n",
    "                score = maxscore\n",
    "\n",
    "            scores.append(score/maxscore)\n",
    "\n",
    "        # create dataframe with filenames for frontal images\n",
    "        df_frontal = pd.DataFrame(img_files, columns = [\"image_path_frontal\"])\n",
    "        df_frontal = df_frontal[df_frontal.image_path_frontal.str.contains('|'.join([\"frontal\"]))==True]\n",
    "        df_frontal[\"no\"] = df_frontal.image_path_frontal.apply(lambda x: x[-19:-4]) # get the unique ending of the filename\n",
    "\n",
    "        # create dataframe with filenames for lateral images\n",
    "        df_lateral = pd.DataFrame(img_files, columns = [\"image_path_lateral\"])\n",
    "        df_lateral = df_lateral[df_lateral.image_path_lateral.str.contains('|'.join([\"lateral\"]))==True]\n",
    "        df_lateral[\"no\"] = df_lateral.image_path_lateral.apply(lambda x: x[-19:-4]) # get the unique ending of the filename\n",
    "\n",
    "        # create dataframe with scores\n",
    "        df_scores = pd.DataFrame(score_files, columns = [\"no\"])\n",
    "        df_scores[\"true scores\"] = scores_true\n",
    "        df_scores[\"score\"] = scores\n",
    "        df_scores.no = df_scores.no.apply(lambda x: x[-19:-4])\n",
    "\n",
    "        # merge the three dataframes\n",
    "        df = df_frontal.merge(df_lateral, how = 'left', on = 'no')\n",
    "        df = df.merge(df_scores, how = 'left', on = 'no')\n",
    "        df = df[df.image_path_frontal.str.contains('|'.join([\"admin\",\"guest\",\"resultTableImage\"]))==False]\n",
    "        df = df[df.image_path_lateral.str.contains('|'.join([\"admin\",\"guest\",\"resultTableImage\"]))==False]\\\n",
    "                .loc[~(df[\"true scores\"]<=0)] # remove all admin and guest files and the images of the results. Remove all black\n",
    "                                    # black images which have a score of 0\n",
    "        #if type is not None:\n",
    "        #    df = df[df.image_path.str.contains('|'.join([type]))==True]\n",
    "        #df.reset_index(drop=True, inplace = True)\n",
    "\n",
    "        df.to_csv(\"data.csv\")\n",
    "\n",
    "        # get path for frontal images\n",
    "        #df_frontal = df[df.image_path.str.contains('|'.join([\"frontal\"]))==True]\n",
    "        frontal_paths = df.image_path_frontal.tolist() #[df.image_path.str.contains('|'.join([\"frontal\"]))==True].tolist()\n",
    "\n",
    "        # get path for lateral images\n",
    "        #df_lateral = df[df.image_path.str.contains('|'.join([\"lateral\"]))==True]\n",
    "        lateral_paths = df.image_path_lateral.tolist()\n",
    "\n",
    "        image_paths = []\n",
    "        for i in range(len(frontal_paths)):\n",
    "          image_paths.append([frontal_paths[i],lateral_paths[i]]) # stack frontal and lateral paths\n",
    "\n",
    "        #image_paths = df.image_path.tolist()\n",
    "        scores_list = df.score.tolist()\n",
    "\n",
    "        image_trainval, image_test, score_trainval, score_test = train_test_split(image_paths, scores_list, test_size=test_size, train_size=train_size, random_state=seed)\n",
    "        image_train, image_val, score_train, score_val = train_test_split(image_trainval, score_trainval, test_size=0.2, train_size=0.8, random_state=seed)\n",
    "\n",
    "        # devide images into train, validation and test set\n",
    "        if split == \"train\":\n",
    "            self.images, self.scores = image_train, score_train\n",
    "        elif split == \"val\":\n",
    "            self.images, self.scores = image_val, score_val\n",
    "        elif split == \"test\":\n",
    "            self.images, self.scores = image_test, score_test\n",
    "        else:\n",
    "          print(\"Please provide either train, val or test as split.\")\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        'Returns the number of samples'\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        'Generate one sample of data'\n",
    "        image_path = self.images[idx]\n",
    "        images = imread_collection([image_path[0], image_path[1]], conserve_memory=True) # stack the frontal and lateral images\n",
    "        score = self.scores[idx]\n",
    "        if self.transform:\n",
    "            #image = transforms.functional.invert(image) # convert image to negative (like Xray images)\n",
    "            #image = self.transform(image) # perform transforms\n",
    "            images = torch.stack([self.transform(img) for img in images], dim = 1) # transform both frontal and lateral images\n",
    "            #images = images.permute(images, (1,0,2,3))\n",
    "        return images, score\n",
    "\n",
    "class CustomInvert:\n",
    "  '''\n",
    "  Rotates the data if need be.\n",
    "  '''\n",
    "  def __init__(self, invert):\n",
    "    # initializing\n",
    "    self.invert = invert\n",
    "\n",
    "  def __call__(self, x):\n",
    "    #assert len(x.shape) == 3, 'x should have [nchannel x rows x cols]'\n",
    "    \n",
    "    if self.invert == True:\n",
    "      x = transforms.functional.invert(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "class npStandardScaler:\n",
    "  def fit(self, x):\n",
    "    self.mean = np.mean(x)\n",
    "    self.std = np.std(x)\n",
    "  def transform(self, x):\n",
    "    x -= self.mean\n",
    "    x /= (self.std + 1e-7)\n",
    "    return x\n",
    "\n",
    "def saliency(input, model):\n",
    "  '''\n",
    "  Calculate the saliency.\n",
    "  '''\n",
    "  input = input.unsqueeze(0) #Add a batch dimension\n",
    "  input = input.to(device)\n",
    "  input.requires_grad = True\n",
    "\n",
    "  score = model(input)\n",
    "  #score, indices = torch.max(preds, 1) # for classification problems\n",
    "\n",
    "  #backward pass to get gradients of score predicted class w.r.t. input image\n",
    "  score.backward()\n",
    "\n",
    "  #get max along channel axis\n",
    "  slc, _ = torch.max(torch.abs(input.grad[0]), dim=0)\n",
    "\n",
    "  #normalize to [0..1]\n",
    "  slc = (slc - slc.min())/(slc.max()-slc.min())\n",
    "\n",
    "  #Detach\n",
    "  im = input.detach().cpu().squeeze(0).numpy()\n",
    "  slc = slc.cpu().numpy()\n",
    "\n",
    "  return im, slc\n",
    "\n",
    "def count_parameters(model):\n",
    "  return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eefe4cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "# initialize scaler\n",
    "scaler = npStandardScaler()\n",
    "\n",
    "repair_type = \"001_hansson_pin_system\"\n",
    "#size = 129 # for baseline\n",
    "#size = 225 # for VGG16\n",
    "size = 300 # for inception v3\n",
    "train_transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                    transforms.Resize((size,size)),\n",
    "                                    #transforms.Grayscale(num_output_channels = 1),\n",
    "                                    transforms.RandomChoice([transforms.GaussianBlur(kernel_size=3, sigma=(1, 1)),\n",
    "                                    transforms.RandomRotation(degrees=(15)),\n",
    "                                    ])])\n",
    "test_transform = val_transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                    transforms.Resize((size,size)),\n",
    "                                    #transforms.Grayscale(num_output_channels = 1),\n",
    "                                    ])\n",
    "\n",
    "train_transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                    transforms.Resize((size,size)),])\n",
    "\n",
    "batch_size = 12\n",
    "\n",
    "# divide data into train-, validation- and testset\n",
    "trainset = SimulationData(repair_type = repair_type, split = \"train\", transform=train_transform)\n",
    "scaler.fit(trainset.scores)\n",
    "trainset.scores = scaler.transform(trainset.scores)\n",
    "train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "valset = SimulationData(repair_type = repair_type, split = \"val\", transform=val_transform)\n",
    "valset.scores = scaler.transform(valset.scores)\n",
    "val_loader = DataLoader(valset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "testset = SimulationData(repair_type=repair_type, split = \"test\", transform=test_transform)\n",
    "testset.scores = scaler.transform(testset.scores)\n",
    "test_loader = DataLoader(testset, batch_size= batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f935d8fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_24233/395363475.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# show some of the first images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnum_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "# show some of the first images\n",
    "images, labels = next(iter(train_loader))\n",
    "plt.figure(figsize=(20,20))\n",
    "\n",
    "num_images = 20\n",
    "\n",
    "for i in range(int(num_images/2)):\n",
    "    plt.subplot(4,5,i+1)\n",
    "    plt.imshow(images[i].permute(1, 2, 3, 0)[0])\n",
    "    plt.title((labels[i].item()*scaler.std)+scaler.mean) # convert back from scaled values\n",
    "\n",
    "for i in range(int(num_images/2)):\n",
    "    plt.subplot(4,5,int(num_images/2) + i+1)\n",
    "    plt.imshow(images[i].permute(1, 2, 3, 0)[1])\n",
    "    plt.title((labels[i].item()*scaler.std)+scaler.mean) # convert back from scaled values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ed5b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models\n",
    "class Baseline(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Baseline, self).__init__()\n",
    "        self.convolutional3d = nn.Sequential(\n",
    "                  # CONV 3D_1\n",
    "                  nn.Conv3d(in_channels=3, out_channels=8, kernel_size=3, stride = 1, padding= 1),\n",
    "                  nn.ReLU(),\n",
    "\n",
    "                  # CONV 3D_2\n",
    "                  nn.Conv3d(in_channels=8, out_channels=16, kernel_size=2, stride = 1, padding= 0),\n",
    "                  nn.ReLU(),\n",
    "        )\n",
    "        self.convolutional = nn.Sequential(\n",
    "                  # CONV 1_1\n",
    "                  nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "                  nn.ReLU(),\n",
    "\n",
    "                  # CONV 1_2\n",
    "                  nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "                  nn.MaxPool2d(kernel_size=2),\n",
    "                  nn.ReLU(),\n",
    "\n",
    "                  # CONV 2_1\n",
    "                  nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "                  nn.ReLU(),\n",
    "\n",
    "                  # CONV 2_2\n",
    "                  nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "                  nn.ReLU(),\n",
    "        )\n",
    "        self.fully_connected = nn.Sequential(\n",
    "                nn.Linear(64*64*64, 1),  \n",
    "                )\n",
    "\n",
    "    def forward(self, x):\n",
    "      x = self.convolutional3d(x)\n",
    "      x = torch.squeeze(x,dim = 2)\n",
    "      x = self.convolutional(x)\n",
    "      x = torch.flatten(x,1)\n",
    "      x = self.fully_connected(x).squeeze()\n",
    "      return x\n",
    "\n",
    "# VGG16 takes an image of 224 x 224 with 3 channels as input\n",
    "class VGG16(nn.Module):\n",
    "  def __init__(self,):\n",
    "    super(VGG16, self).__init__()\n",
    "\n",
    "    self.convolutional3d_2_2d = nn.Sequential(\n",
    "                  # CONV 3D_1\n",
    "                  nn.Conv3d(in_channels=3, out_channels=8, kernel_size=3, stride = 1, padding= 1),\n",
    "                  nn.ReLU(inplace=True),\n",
    "\n",
    "                  # CONV 3D_2\n",
    "                  nn.Conv3d(in_channels=8, out_channels=3, kernel_size=2, stride = 1, padding= 0),\n",
    "                  nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    self.vgg16 = torchvision.models.vgg16(pretrained=True)\n",
    "\n",
    "    #Freeze the parameters (by using this method, you can freeze the parameters in the convolutional layers and/or the fully connected layers)\n",
    "    for param in self.vgg16.parameters(): # convolutional\n",
    "      param.requires_grad = False\n",
    "\n",
    "    #for param in self.vgg16.classifier.parameters(): # fully connected\n",
    "    #  param.requires_grad = False\n",
    "\n",
    "    #Modify the last layer\n",
    "    n_features = self.vgg16.classifier[3].in_features #Number of features (inputs) in the last layer we want to keep\n",
    "    features = list(self.vgg16.classifier.children())[:-4] # remove the last two FC layers\n",
    "    features.extend([nn.Linear(n_features, 1)]) #1 output (numeric)\n",
    "    self.vgg16.classifier = nn.Sequential(*features)\n",
    "    \n",
    "  def forward(self, x):\n",
    "    x = self.convolutional3d_2_2d(x)\n",
    "    x = self.vgg16(x.squeeze())\n",
    "    return x.squeeze()\n",
    "\n",
    "# Inception v-3 takes an image of 299 x 299 with 3 channels as input\n",
    "class Inception_v3(nn.Module):\n",
    "  def __init__(self,):\n",
    "    super(Inception_v3, self).__init__()\n",
    "\n",
    "    self.convolutional3d_2_2d = nn.Sequential(\n",
    "                  # CONV 3D_1\n",
    "                  nn.Conv3d(in_channels=3, out_channels=8, kernel_size=3, stride = 1, padding= 1),\n",
    "                  nn.ReLU(inplace=True),\n",
    "\n",
    "                  # CONV 3D_2\n",
    "                  nn.Conv3d(in_channels=8, out_channels=3, kernel_size=2, stride = 1, padding= 0),\n",
    "                  nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    self.inception = torchvision.models.inception_v3(pretrained=True)\n",
    "\n",
    "    #Freeze the parameters\n",
    "    for param in self.inception.parameters():\n",
    "      param.require_grad = False\n",
    "\n",
    "    #Remove the last layer\n",
    "    n_features = self.inception.fc.in_features #Number of features (inputs) in the last layer\n",
    "    self.inception.fc = nn.Linear(n_features,1)\n",
    "    \n",
    "  def forward(self, x):\n",
    "    x = self.convolutional3d_2_2d(x)\n",
    "    x = self.inception(x.squeeze())\n",
    "    return x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1130105f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Inception_v3()\n",
    "model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
    "decayRate = 0.96\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=decayRate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c322096c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model): \n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a749e5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = VGG16()\n",
    "# model.to(device)\n",
    "# num_epochs = 50\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
    "# decayRate = 0.96\n",
    "# scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=decayRate)\n",
    "\n",
    "num_epochs = 2\n",
    "\n",
    "out_dict = train(model, optimizer, train_loader, val_loader, num_epochs=num_epochs, validation = True, scheduler=scheduler)\n",
    "#out_dict = train(model, optimizer, num_epochs, validation= True, scheduler=scheduler) # scheduler = scheduler)\n",
    "\n",
    "wandb.config = {\n",
    "  \"learning_rate\": scheduler.get_last_lr()[0],\n",
    "  \"epochs\": num_epochs,\n",
    "  \"batch_size\": batch_size\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40eedd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, train_labels = next(iter(train_loader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "\n",
    "\n",
    "images, labels = next(iter(test_loader))\n",
    "outputs = model(images)\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "\n",
    "num_images = 20\n",
    "\n",
    "for i in range(int(num_images/2)):\n",
    "    plt.subplot(4,5,i+1)\n",
    "    plt.imshow(images[i].permute(1, 2, 3, 0)[0])\n",
    "    plt.title(f'{(labels[i].item()*scaler.std)+scaler.mean:.3f}, {(outputs[i].item()*scaler.std)+scaler.mean:.3f}')\n",
    "\n",
    "for i in range(int(num_images/2)):\n",
    "    plt.subplot(4,5,int(num_images/2) + i+1)\n",
    "    plt.imshow(images[i].permute(1, 2, 3, 0)[1])\n",
    "    plt.title(f'{(labels[i].item()*scaler.std)+scaler.mean:.3f}, {(outputs[i].item()*scaler.std)+scaler.mean:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4c119a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "test_scores = []\n",
    "for i in range(testset.__len__()):\n",
    "    _, tmp = testset.__getitem__(i)\n",
    "    test_scores.append((tmp*scaler.std)+scaler.mean)\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.title(\"True distribution of test scores\")\n",
    "plt.hist(test_scores, bins = 40)\n",
    "\n",
    "test_predict = []\n",
    "for minibatch_no, (data, target) in enumerate(test_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            #Forward pass your image through the network\n",
    "            output = model(data)\n",
    "            for i in range(len(output)):\n",
    "                test_predict.append((output[i].item()*scaler.std)+scaler.mean)\n",
    "\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"Predicted distribution of test scores\")\n",
    "plt.hist(test_predict, bins = 40)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30786818",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 10\n",
    "\n",
    "images, _ = testset.__getitem__(idx)\n",
    "_, model_slc = saliency(images, model)\n",
    "\n",
    "plt.figure(figsize = (10,10))\n",
    "plt.subplot(2,2,1)\n",
    "plt.imshow(images.permute(1, 2, 3, 0)[0])\n",
    "plt.title(f'{(labels[idx].item()*scaler.std)+scaler.mean:.3f}, {(outputs[idx].item()*scaler.std)+scaler.mean:.3f}')\n",
    "plt.imshow(model_slc[0], cmap = plt.cm.hot, alpha = 0.5)\n",
    "plt.subplot(2,2,2)\n",
    "plt.title('Saliency map frontal')\n",
    "plt.imshow(model_slc[0], cmap = plt.cm.hot)\n",
    "plt.subplot(2,2,3)\n",
    "plt.imshow(images.permute(1, 2, 3, 0)[1])\n",
    "plt.title(f'{(labels[idx].item()*scaler.std)+scaler.mean:.3f}, {(outputs[idx].item()*scaler.std)+scaler.mean:.3f}')\n",
    "plt.imshow(model_slc[1], cmap = plt.cm.hot, alpha = 0.5)\n",
    "plt.subplot(2,2,4)\n",
    "plt.title('Saliency map lateral')\n",
    "plt.imshow(model_slc[1], cmap = plt.cm.hot)\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650c1e41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
