{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8ebfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preamble\n",
    "import glob\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "from utils import train, predict, score_fluoroscopy, score_time, score_xray, score_retries_cannulated_dhs, score_retries_hansson, \\\n",
    "                drill_dist_hansson, guidewire_dist, drill_dist_hansson\n",
    "from skimage.io import imread_collection\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from unittest import TestLoader\n",
    "import numpy as np\n",
    "import glob\n",
    "import PIL.Image as Image\n",
    "from tqdm.notebook import tqdm\n",
    "plt.style.use('seaborn')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56d4e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up weights and biases (wandb.ai)\n",
    "\n",
    "import wandb\n",
    "\n",
    "wandb.init(project = \"ort-project\", entity = \"ditteblom\", reinit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b700a1",
   "metadata": {},
   "source": [
    "Create the dataset as a torch dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41eca80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class SimulationData(torch.utils.data.Dataset):\n",
    "    def __init__(self, repair_type, split, transform = None, data_path = \"Data\", train_size = 0.8, test_size = 0.2, seed = 8):\n",
    "        'Initializing data'\n",
    "        self.data_path = data_path\n",
    "        self.repair_type = repair_type + \"/001_copenahgen_test_1\"\n",
    "        #self.type = type\n",
    "        self.transform = transform\n",
    "\n",
    "        img_files = glob.glob(self.data_path + '***/**/*.jpg', recursive=True)\n",
    "        img_files = [ x for x in img_files if self.repair_type in x ]\n",
    "        score_files = glob.glob(self.data_path + '***/**/*.txt', recursive=True)\n",
    "        score_files = [ x for x in score_files if self.repair_type in x ]\n",
    "        scores = []\n",
    "        scores_true = []\n",
    "        maxscore = 0\n",
    "                \n",
    "        for file in score_files:\n",
    "            with open(file) as f:\n",
    "                lines = f.read()\n",
    "            idx_score_end = lines.find('Score')\n",
    "            tmp = lines[:idx_score_end]\n",
    "            idx_score_start = tmp.rfind('\\n')\n",
    "            score = np.double(lines[idx_score_start+1:idx_score_end-4])\n",
    "\n",
    "            if maxscore == 0:\n",
    "              idx_maxscore_end = lines.find('Max score')\n",
    "              tmp = lines[:idx_maxscore_end]\n",
    "              idx_maxscore_start = tmp.rfind('\\n')\n",
    "              maxscore = np.double(lines[idx_maxscore_start+1:idx_maxscore_end-3])\n",
    "\n",
    "            scores_true.append(score/maxscore)\n",
    "\n",
    "            # find variables to be corrected in score\n",
    "            if repair_type == \"001_hansson_pin_system\":\n",
    "              var_score = []\n",
    "              variables = [\"Fluoroscopy\", \"Total time\", \"Nr of X-rays\", \"Nr of retries\", \"Distal drill distance to joint surface (mm)\",\n",
    "                          \"Guide wire distance to joint surface (mm)\", \"Proximal drill distance to joint surface (mm)\"]\n",
    "              for var in variables:\n",
    "                idx_end = lines.find(var)\n",
    "                tmp = lines[:idx_end]\n",
    "                idx_start = tmp.rfind('\\n')\n",
    "                var_score.append(np.double(lines[idx_start+1:idx_end-4]))\n",
    "\n",
    "              score += score_fluoroscopy(var_score[0])\n",
    "              score += score_time(var_score[1])\n",
    "              score += score_xray(var_score[2])\n",
    "              score += score_retries_hansson(var_score[3])\n",
    "              score += drill_dist_hansson(var_score[4])\n",
    "              score += guidewire_dist(var_score[5])\n",
    "              score += drill_dist_hansson(var_score[6])\n",
    "\n",
    "              if score > maxscore:\n",
    "                score = maxscore\n",
    "\n",
    "            scores.append(score/maxscore)\n",
    "\n",
    "        # create dataframe with filenames for frontal images\n",
    "        df_frontal = pd.DataFrame(img_files, columns = [\"image_path_frontal\"])\n",
    "        df_frontal = df_frontal[df_frontal.image_path_frontal.str.contains('|'.join([\"frontal\"]))==True]\n",
    "        df_frontal[\"no\"] = df_frontal.image_path_frontal.apply(lambda x: x[-19:-4]) # get the unique ending of the filename\n",
    "\n",
    "        # create dataframe with filenames for lateral images\n",
    "        df_lateral = pd.DataFrame(img_files, columns = [\"image_path_lateral\"])\n",
    "        df_lateral = df_lateral[df_lateral.image_path_lateral.str.contains('|'.join([\"lateral\"]))==True]\n",
    "        df_lateral[\"no\"] = df_lateral.image_path_lateral.apply(lambda x: x[-19:-4]) # get the unique ending of the filename\n",
    "\n",
    "        # create dataframe with scores\n",
    "        df_scores = pd.DataFrame(score_files, columns = [\"no\"])\n",
    "        df_scores[\"true scores\"] = scores_true\n",
    "        df_scores[\"score\"] = scores\n",
    "        df_scores.no = df_scores.no.apply(lambda x: x[-19:-4])\n",
    "\n",
    "        # merge the three dataframes\n",
    "        df = df_frontal.merge(df_lateral, how = 'left', on = 'no')\n",
    "        df = df.merge(df_scores, how = 'left', on = 'no')\n",
    "        df = df[df.image_path_frontal.str.contains('|'.join([\"admin\",\"guest\",\"resultTableImage\"]))==False]\n",
    "        df = df[df.image_path_lateral.str.contains('|'.join([\"admin\",\"guest\",\"resultTableImage\"]))==False]\\\n",
    "                .loc[~(df[\"true scores\"]<=0)] # remove all admin and guest files and the images of the results. Remove all black\n",
    "                                    # black images which have a score of 0\n",
    "        #if type is not None:\n",
    "        #    df = df[df.image_path.str.contains('|'.join([type]))==True]\n",
    "        #df.reset_index(drop=True, inplace = True)\n",
    "\n",
    "        df.to_csv(\"data.csv\")\n",
    "\n",
    "        # get path for frontal images\n",
    "        #df_frontal = df[df.image_path.str.contains('|'.join([\"frontal\"]))==True]\n",
    "        frontal_paths = df.image_path_frontal.tolist() #[df.image_path.str.contains('|'.join([\"frontal\"]))==True].tolist()\n",
    "\n",
    "        # get path for lateral images\n",
    "        #df_lateral = df[df.image_path.str.contains('|'.join([\"lateral\"]))==True]\n",
    "        lateral_paths = df.image_path_lateral.tolist()\n",
    "\n",
    "        image_paths = []\n",
    "        for i in range(len(frontal_paths)):\n",
    "          image_paths.append([frontal_paths[i],lateral_paths[i]]) # stack frontal and lateral paths\n",
    "\n",
    "        #image_paths = df.image_path.tolist()\n",
    "        scores_list = df.score.tolist()\n",
    "\n",
    "        image_trainval, image_test, score_trainval, score_test = train_test_split(image_paths, scores_list, test_size=test_size, train_size=train_size, random_state=seed)\n",
    "        image_train, image_val, score_train, score_val = train_test_split(image_trainval, score_trainval, test_size=0.2, train_size=0.8, random_state=seed)\n",
    "\n",
    "        # devide images into train, validation and test set\n",
    "        if split == \"train\":\n",
    "            self.images, self.scores = image_train, score_train\n",
    "        elif split == \"val\":\n",
    "            self.images, self.scores = image_val, score_val\n",
    "        elif split == \"test\":\n",
    "            self.images, self.scores = image_test, score_test\n",
    "        else:\n",
    "          print(\"Please provide either train, val or test as split.\")\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        'Returns the number of samples'\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        'Generate one sample of data'\n",
    "        image_path = self.images[idx]\n",
    "        images = imread_collection([image_path[0], image_path[1]], conserve_memory=True) # stack the frontal and lateral images\n",
    "        score = self.scores[idx]\n",
    "        if self.transform:\n",
    "            #image = transforms.functional.invert(image) # convert image to negative (like Xray images)\n",
    "            #image = self.transform(image) # perform transforms\n",
    "            images = torch.stack([self.transform(img) for img in images], dim = 1) # transform both frontal and lateral images\n",
    "            #images = images.permute(images, (1,0,2,3))\n",
    "        return images, score\n",
    "\n",
    "class CustomInvert:\n",
    "  '''\n",
    "  Rotates the data if need be.\n",
    "  '''\n",
    "  def __init__(self, invert):\n",
    "    # initializing\n",
    "    self.invert = invert\n",
    "\n",
    "  def __call__(self, x):\n",
    "    #assert len(x.shape) == 3, 'x should have [nchannel x rows x cols]'\n",
    "    \n",
    "    if self.invert == True:\n",
    "      x = transforms.functional.invert(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "class npStandardScaler:\n",
    "  def fit(self, x):\n",
    "    self.mean = np.mean(x)\n",
    "    self.std = np.std(x)\n",
    "  def transform(self, x):\n",
    "    x -= self.mean\n",
    "    x /= (self.std + 1e-7)\n",
    "    return x\n",
    "\n",
    "def saliency(input, model):\n",
    "  '''\n",
    "  Calculate the saliency.\n",
    "  '''\n",
    "  input = input.unsqueeze(0) #Add a batch dimension\n",
    "  input = input.to(device)\n",
    "  input.requires_grad = True\n",
    "\n",
    "  score = model(input)\n",
    "  #score, indices = torch.max(preds, 1) # for classification problems\n",
    "\n",
    "  #backward pass to get gradients of score predicted class w.r.t. input image\n",
    "  score.backward()\n",
    "\n",
    "  #get max along channel axis\n",
    "  slc, _ = torch.max(torch.abs(input.grad[0]), dim=0)\n",
    "\n",
    "  #normalize to [0..1]\n",
    "  slc = (slc - slc.min())/(slc.max()-slc.min())\n",
    "\n",
    "  #Detach\n",
    "  im = input.detach().cpu().squeeze(0).numpy()\n",
    "  slc = slc.cpu().numpy()\n",
    "\n",
    "  return im, slc\n",
    "\n",
    "def count_parameters(model):\n",
    "  return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefe4cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "# initialize scaler\n",
    "scaler = npStandardScaler()\n",
    "\n",
    "repair_type = \"001_hansson_pin_system\"\n",
    "#size = 129 # for baseline\n",
    "#size = 225 # for VGG16\n",
    "size = 300 # for inception v3\n",
    "train_transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                    transforms.Resize((size,size)),\n",
    "                                    #transforms.Grayscale(num_output_channels = 1),\n",
    "                                    transforms.RandomChoice([transforms.GaussianBlur(kernel_size=3, sigma=(1, 1)),\n",
    "                                    transforms.RandomRotation(degrees=(15)),\n",
    "                                    ])])\n",
    "test_transform = val_transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                    transforms.Resize((size,size)),\n",
    "                                    #transforms.Grayscale(num_output_channels = 1),\n",
    "                                    ])\n",
    "\n",
    "train_transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                    transforms.Resize((size,size)),])\n",
    "\n",
    "batch_size = 12\n",
    "\n",
    "# divide data into train-, validation- and testset\n",
    "trainset = SimulationData(repair_type = repair_type, split = \"train\", transform=train_transform)\n",
    "scaler.fit(trainset.scores)\n",
    "trainset.scores = scaler.transform(trainset.scores)\n",
    "train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "valset = SimulationData(repair_type = repair_type, split = \"val\", transform=val_transform)\n",
    "valset.scores = scaler.transform(valset.scores)\n",
    "val_loader = DataLoader(valset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "testset = SimulationData(repair_type=repair_type, split = \"test\", transform=test_transform)\n",
    "testset.scores = scaler.transform(testset.scores)\n",
    "test_loader = DataLoader(testset, batch_size= batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f935d8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show some of the first images\n",
    "images, labels = next(iter(train_loader))\n",
    "plt.figure(figsize=(20,20))\n",
    "\n",
    "num_images = 20\n",
    "\n",
    "for i in range(int(num_images/2)):\n",
    "    plt.subplot(4,5,i+1)\n",
    "    plt.imshow(images[i].permute(1, 2, 3, 0)[0])\n",
    "    plt.title((labels[i].item()*scaler.std)+scaler.mean) # convert back from scaled values\n",
    "\n",
    "for i in range(int(num_images/2)):\n",
    "    plt.subplot(4,5,int(num_images/2) + i+1)\n",
    "    plt.imshow(images[i].permute(1, 2, 3, 0)[1])\n",
    "    plt.title((labels[i].item()*scaler.std)+scaler.mean) # convert back from scaled values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ed5b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models\n",
    "class Baseline(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Baseline, self).__init__()\n",
    "        self.convolutional3d = nn.Sequential(\n",
    "                  # CONV 3D_1\n",
    "                  nn.Conv3d(in_channels=3, out_channels=8, kernel_size=3, stride = 1, padding= 1),\n",
    "                  nn.ReLU(),\n",
    "\n",
    "                  # CONV 3D_2\n",
    "                  nn.Conv3d(in_channels=8, out_channels=16, kernel_size=2, stride = 1, padding= 0),\n",
    "                  nn.ReLU(),\n",
    "        )\n",
    "        self.convolutional = nn.Sequential(\n",
    "                  # CONV 1_1\n",
    "                  nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "                  nn.ReLU(),\n",
    "\n",
    "                  # CONV 1_2\n",
    "                  nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "                  nn.MaxPool2d(kernel_size=2),\n",
    "                  nn.ReLU(),\n",
    "\n",
    "                  # CONV 2_1\n",
    "                  nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "                  nn.ReLU(),\n",
    "\n",
    "                  # CONV 2_2\n",
    "                  nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "                  nn.ReLU(),\n",
    "        )\n",
    "        self.fully_connected = nn.Sequential(\n",
    "                nn.Linear(64*64*64, 1),  \n",
    "                )\n",
    "\n",
    "    def forward(self, x):\n",
    "      x = self.convolutional3d(x)\n",
    "      x = torch.squeeze(x,dim = 2)\n",
    "      x = self.convolutional(x)\n",
    "      x = torch.flatten(x,1)\n",
    "      x = self.fully_connected(x).squeeze()\n",
    "      return x\n",
    "\n",
    "# VGG16 takes an image of 224 x 224 with 3 channels as input\n",
    "class VGG16(nn.Module):\n",
    "  def __init__(self,):\n",
    "    super(VGG16, self).__init__()\n",
    "\n",
    "    self.convolutional3d_2_2d = nn.Sequential(\n",
    "                  # CONV 3D_1\n",
    "                  nn.Conv3d(in_channels=3, out_channels=8, kernel_size=3, stride = 1, padding= 1),\n",
    "                  nn.ReLU(inplace=True),\n",
    "\n",
    "                  # CONV 3D_2\n",
    "                  nn.Conv3d(in_channels=8, out_channels=3, kernel_size=2, stride = 1, padding= 0),\n",
    "                  nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    self.vgg16 = torchvision.models.vgg16(pretrained=True)\n",
    "\n",
    "    #Freeze the parameters (by using this method, you can freeze the parameters in the convolutional layers and/or the fully connected layers)\n",
    "    for param in self.vgg16.parameters(): # convolutional\n",
    "      param.requires_grad = False\n",
    "\n",
    "    #for param in self.vgg16.classifier.parameters(): # fully connected\n",
    "    #  param.requires_grad = False\n",
    "\n",
    "    #Modify the last layer\n",
    "    n_features = self.vgg16.classifier[3].in_features #Number of features (inputs) in the last layer we want to keep\n",
    "    features = list(self.vgg16.classifier.children())[:-4] # remove the last two FC layers\n",
    "    features.extend([nn.Linear(n_features, 1)]) #1 output (numeric)\n",
    "    self.vgg16.classifier = nn.Sequential(*features)\n",
    "    \n",
    "  def forward(self, x):\n",
    "    x = self.convolutional3d_2_2d(x)\n",
    "    x = self.vgg16(x.squeeze())\n",
    "    return x.squeeze()\n",
    "\n",
    "# Inception v-3 takes an image of 299 x 299 with 3 channels as input\n",
    "class Inception_v3(nn.Module):\n",
    "  def __init__(self,):\n",
    "    super(Inception_v3, self).__init__()\n",
    "\n",
    "    self.convolutional3d_2_2d = nn.Sequential(\n",
    "                  # CONV 3D_1\n",
    "                  nn.Conv3d(in_channels=3, out_channels=8, kernel_size=3, stride = 1, padding= 1),\n",
    "                  nn.ReLU(inplace=True),\n",
    "\n",
    "                  # CONV 3D_2\n",
    "                  nn.Conv3d(in_channels=8, out_channels=3, kernel_size=2, stride = 1, padding= 0),\n",
    "                  nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    self.inception = torchvision.models.inception_v3(pretrained=True)\n",
    "\n",
    "    #Freeze the parameters\n",
    "    for param in self.inception.parameters():\n",
    "      param.require_grad = False\n",
    "\n",
    "    #Remove the last layer\n",
    "    n_features = self.inception.fc.in_features #Number of features (inputs) in the last layer\n",
    "    self.inception.fc = nn.Linear(n_features,1)\n",
    "    \n",
    "  def forward(self, x):\n",
    "    x = self.convolutional3d_2_2d(x)\n",
    "    x = self.inception(x.squeeze())\n",
    "    return x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1130105f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Inception_v3()\n",
    "model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
    "decayRate = 0.96\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=decayRate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c322096c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model): \n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a749e5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = VGG16()\n",
    "# model.to(device)\n",
    "# num_epochs = 50\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
    "# decayRate = 0.96\n",
    "# scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=decayRate)\n",
    "\n",
    "num_epochs = 2\n",
    "\n",
    "out_dict = train(model, optimizer, train_loader, val_loader, num_epochs=num_epochs, validation = True, scheduler=scheduler)\n",
    "#out_dict = train(model, optimizer, num_epochs, validation= True, scheduler=scheduler) # scheduler = scheduler)\n",
    "\n",
    "wandb.config = {\n",
    "  \"learning_rate\": scheduler.get_last_lr()[0],\n",
    "  \"epochs\": num_epochs,\n",
    "  \"batch_size\": batch_size\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40eedd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, train_labels = next(iter(train_loader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "\n",
    "\n",
    "images, labels = next(iter(test_loader))\n",
    "outputs = model(images)\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "\n",
    "num_images = 20\n",
    "\n",
    "for i in range(int(num_images/2)):\n",
    "    plt.subplot(4,5,i+1)\n",
    "    plt.imshow(images[i].permute(1, 2, 3, 0)[0])\n",
    "    plt.title(f'{(labels[i].item()*scaler.std)+scaler.mean:.3f}, {(outputs[i].item()*scaler.std)+scaler.mean:.3f}')\n",
    "\n",
    "for i in range(int(num_images/2)):\n",
    "    plt.subplot(4,5,int(num_images/2) + i+1)\n",
    "    plt.imshow(images[i].permute(1, 2, 3, 0)[1])\n",
    "    plt.title(f'{(labels[i].item()*scaler.std)+scaler.mean:.3f}, {(outputs[i].item()*scaler.std)+scaler.mean:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4c119a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "test_scores = []\n",
    "for i in range(testset.__len__()):\n",
    "    _, tmp = testset.__getitem__(i)\n",
    "    test_scores.append((tmp*scaler.std)+scaler.mean)\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.title(\"True distribution of test scores\")\n",
    "plt.hist(test_scores, bins = 40)\n",
    "\n",
    "test_predict = []\n",
    "for minibatch_no, (data, target) in enumerate(test_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            #Forward pass your image through the network\n",
    "            output = model(data)\n",
    "            for i in range(len(output)):\n",
    "                test_predict.append((output[i].item()*scaler.std)+scaler.mean)\n",
    "\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"Predicted distribution of test scores\")\n",
    "plt.hist(test_predict, bins = 40)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30786818",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 10\n",
    "\n",
    "images, _ = testset.__getitem__(idx)\n",
    "_, model_slc = saliency(images, model)\n",
    "\n",
    "plt.figure(figsize = (10,10))\n",
    "plt.subplot(2,2,1)\n",
    "plt.imshow(images.permute(1, 2, 3, 0)[0])\n",
    "plt.title(f'{(labels[idx].item()*scaler.std)+scaler.mean:.3f}, {(outputs[idx].item()*scaler.std)+scaler.mean:.3f}')\n",
    "plt.imshow(model_slc[0], cmap = plt.cm.hot, alpha = 0.5)\n",
    "plt.subplot(2,2,2)\n",
    "plt.title('Saliency map frontal')\n",
    "plt.imshow(model_slc[0], cmap = plt.cm.hot)\n",
    "plt.subplot(2,2,3)\n",
    "plt.imshow(images.permute(1, 2, 3, 0)[1])\n",
    "plt.title(f'{(labels[idx].item()*scaler.std)+scaler.mean:.3f}, {(outputs[idx].item()*scaler.std)+scaler.mean:.3f}')\n",
    "plt.imshow(model_slc[1], cmap = plt.cm.hot, alpha = 0.5)\n",
    "plt.subplot(2,2,4)\n",
    "plt.title('Saliency map lateral')\n",
    "plt.imshow(model_slc[1], cmap = plt.cm.hot)\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650c1e41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
